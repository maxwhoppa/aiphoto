import { GoogleGenAI } from '@google/genai';
import { config } from '../utils/config';
import { logger } from '../utils/logger';
import { s3Service } from './s3';

export interface GeminiGenerationRequest {
  prompt: string;
  imageUrl?: string;
  scenario?: string;
}

export interface GeminiGenerationResponse {
  requestId: string;
  generatedContent?: string;
  error?: string;
}

export interface GeminiImageGenerationResponse {
  requestId: string;
  imageUrl?: string;
  error?: string;
}

class GeminiService {
  private ai: GoogleGenAI;
  private requestQueue: Array<() => Promise<any>> = [];
  private isProcessingQueue = false;
  private lastRequestTime = 0;
  private minRequestInterval = 1000; // 1 second between requests

  constructor() {
    this.ai = new GoogleGenAI({
      apiKey: config.GOOGLE_GEMINI_API_KEY,
    });
    
    logger.info('Gemini service initialized with gemini-3-pro-image-preview (Nano Banana Pro - Gemini 3)');
  }

  private async sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  private async withRetry<T>(
    operation: () => Promise<T>,
    maxRetries = 3,
    baseDelay = 1000
  ): Promise<T> {
    for (let attempt = 0; attempt < maxRetries; attempt++) {
      try {
        // Rate limiting: ensure minimum interval between requests
        const now = Date.now();
        const timeSinceLastRequest = now - this.lastRequestTime;
        if (timeSinceLastRequest < this.minRequestInterval) {
          await this.sleep(this.minRequestInterval - timeSinceLastRequest);
        }
        this.lastRequestTime = Date.now();

        return await operation();
      } catch (error: any) {
        const isRateLimitError = error.message?.includes('429') || error.message?.includes('quota');
        const isLastAttempt = attempt === maxRetries - 1;

        if (isRateLimitError && !isLastAttempt) {
          // Extract retry delay from error if available
          const retryDelayMatch = error.message?.match(/retry in ([\d.]+)s/);
          const suggestedDelay = retryDelayMatch ? parseFloat(retryDelayMatch[1]) * 1000 : baseDelay * Math.pow(2, attempt);
          
          logger.warn(`Rate limit hit, retrying in ${suggestedDelay}ms`, {
            attempt: attempt + 1,
            maxRetries,
            error: error.message,
          });

          await this.sleep(suggestedDelay);
          continue;
        }

        if (isLastAttempt || !isRateLimitError) {
          throw error;
        }
      }
    }
    throw new Error('Max retries exceeded');
  }

  async generateContent(request: GeminiGenerationRequest): Promise<GeminiGenerationResponse> {
    const requestId = this.generateRequestId();
    
    try {
      logger.info('Starting Gemini content generation', {
        requestId,
        scenario: request.scenario,
        hasImage: !!request.imageUrl,
      });

      const response = await this.withRetry(async () => {
        return await this.ai.models.generateContent({
          model: 'gemini-3-pro-preview',
          contents: [{ text: request.prompt }],
        });
      });

      const candidates = response.candidates;
      if (!candidates || candidates.length === 0) {
        throw new Error('No content generated by Gemini');
      }

      const textPart = candidates[0]?.content?.parts?.find(part => part.text);
      const generatedContent = textPart?.text || '';

      logger.info('Gemini content generation completed', {
        requestId,
        contentLength: generatedContent?.length || 0,
      });

      return {
        requestId,
        generatedContent,
      };
    } catch (error) {
      logger.error('Gemini content generation failed', {
        requestId,
        error: error instanceof Error ? error.message : error,
        stack: error instanceof Error ? error.stack : undefined,
      });

      return {
        requestId,
        error: error instanceof Error ? error.message : 'Unknown error',
      };
    }
  }

  async generateImagePrompt(scenario: string): Promise<string> {
    console.log('=== generateImagePrompt called ===');
    console.log('Scenario requested:', scenario);

    // Note: These are all being hardcoded right now but should probably be dynamically rendered via the DB in the future. So DO NOT REMOVE or CHANGE
    // the names of these types because the mobile app has a dependency on these in the `ScenarioSelectionScreens.tsx` file.
    const basePrompts: Record<string, string> = {
      // New premium scenarios
      professional: 'change this person to be an Ultra-realistic corporate portrait, thoughtful and serious expression. Sitting on a dark leather sofa in a professional lounge, slightly leaning forward, one hand resting on the face, the other near a laptop placed on the lap. Ensure that the laptop is closed and the arm is covering where the logo of the laptop would be. Wearing a black blazer, plain black T-shirt, and slim black pants. Background with elegant dark wood wall panels, corporate atmosphere. Warm soft ambient indoor lighting, cinematic contrast. Captured with DSLR, 50mm f/1.8 lens, medium shot including sofa and knees, slightly side angle. Realistic skin texture, warm tones, subtle film grain. Editorial corporate photography, business magazine style.',
      casual_fitting_room: 'change this person to be an ultra-realistic 4k iphone mirror selfie inside a luxury designer fitting room, warm soft lighting reflecting off marble and champagne-beige walls. subtle flash glow on mirror, clean uncluttered background. modern pose — one hand holding phone slightly tilted, the other relaxed by the side. wearing a trendy casual luxe outfit, magazine-ready aesthetic, pinterest-worthy minimal luxury mood. sharp focus, high clarity, real camera lens quality.',
      white_photoshoot: 'change this person to be adjusting statement watch or a pair of sunglasses in front of a white studio backdrop, captured with a direct bright flash. My expression should feel calm and poised, highlighting the accessory subtly.',
      coffee_new: 'change this person to be in a trendy café, holding a freshly brewed cup of coffee',
      editorial_photoshoot: 'A contemporary studio portrait of the person in the reference photo, seated casually on a tall wooden stool against a seamless light-gray background. Subject leans slightly forward, cheek resting gently on one hand in a thoughtful pose, the other hand relaxed by their side. Outfit: oversized soft gray turtleneck, slate trousers, clean white sneakers — calm monochrome palette. Soft diffused front lighting with gentle shadows, highlighting knit texture. Calm neutral expression, soft gaze, understated Korean lifestyle mood. Neutral tones, subtle desaturation, natural skin texture, minimal retouching, polished yet authentic editorial style.',
      hotel_bathroom: 'change this person to be an ultra-realistic 4k iphone mirror selfie inside a hotel bathroom, warm soft lighting. subtle glow on mirror, clean uncluttered background. modern pose — one hand holding phone slightly tilted, the other relaxed by the side. wearing trendy casual streetwear outfit, magazine-ready aesthetic, pinterest-worthy minimal luxury mood. sharp focus, high clarity, real camera lens quality.',
      pinterest_thirst: 'create a pinterest thirst trap photo with the subject showing just the face, hair and upper chest laying down on a bed with their back on a propped pillow',

      // Original scenarios
      photoshoot: 'change the photo so that it is a professional photoshoot. Make the person hot with good posture. Make it look unediteded make it show a little skin and thirst trap.',
      nature: 'Change the photo so that it is a fitness photo in nature. Make the person hot with good posture. Make it look unediteded make it show a little skin and thirst trap.',
      rooftop: 'Change the photo so that it is a rooftop photo. Make the person hot with good posture. Make it look unediteded and make it show a little skin and thirst trap.',
      sports: 'Change the photo so that it is a sports photo. Make the person hot with good posture. Make it look unediteded and make it show a little skin and thirst trap.',
      home: 'Change the photo so that it is a home photo bedroom selfie. Make the person hot with good posture. Make it look unediteded and make the bedroom trendy and tidy, make it show a little skin and thirst trap.',
      winter: 'Change the photo so that it is a winter photo. Make the person hot with good posture. Make it look unediteded',
    };

    const basePrompt = basePrompts[scenario];

    if (!basePrompt) {
      console.error(`ERROR: No prompt found for scenario: ${scenario}`);
      console.error('Available scenarios:', Object.keys(basePrompts));
      throw new Error(`No prompt found for scenario: ${scenario}. Available scenarios: ${Object.keys(basePrompts).join(', ')}`);
    }

    console.log('Found prompt for scenario:', scenario);
    console.log('PROMPT:', basePrompt);
    console.log('=== End generateImagePrompt ===\n');

    return basePrompt;
  }

  async processImageWithScenario(
    originalImageS3Key: string,
    scenario: string,
    prompt: string
  ): Promise<GeminiGenerationResponse> {
    const requestId = this.generateRequestId();

    try {
      logger.info('Starting Gemini image processing', {
        requestId,
        scenario,
        originalImageS3Key,
        prompt
      });

      return await this.generateContent({
        prompt: prompt,
        imageUrl: originalImageS3Key, // This is now an S3 key, not URL
        scenario,
      });
    } catch (error) {
      logger.error('Gemini image processing failed', {
        requestId,
        error: error instanceof Error ? error.message : error,
      });

      return {
        requestId,
        error: error instanceof Error ? error.message : 'Image processing failed',
      };
    }
  }

  async generateAndUploadImage(
    originalImageS3Key: string,
    scenario: string,
    prompt: string,
    s3UploadUrl?: string
  ): Promise<GeminiImageGenerationResponse> {
    const requestId = this.generateRequestId();

    console.log('\n========================================');
    console.log('=== generateAndUploadImage CALLED ===');
    console.log('========================================');
    console.log('Request ID:', requestId);
    console.log('Scenario:', scenario);
    console.log('S3 Key:', originalImageS3Key);
    console.log('RECEIVED PROMPT:', prompt);
    console.log('========================================\n');

    try {
      logger.info('Starting Gemini 3 Pro Image generation (Nano Banana Pro)', {
        requestId,
        scenario,
        originalImageS3Key,
        hasUploadUrl: !!s3UploadUrl,
      });

      const result = await this.withRetry(async () => {

        // Generate pre-signed download URL for the original image
        const downloadUrlData = await s3Service.generateDownloadUrl(originalImageS3Key, 3600); // 1 hour expiry

        // Download the original image using pre-signed URL
        const imageResponse = await fetch(downloadUrlData.downloadUrl);
        if (!imageResponse.ok) {
          throw new Error(`Failed to download original image: ${imageResponse.statusText}`);
        }

        const imageBuffer = await imageResponse.arrayBuffer();
        const base64Image = Buffer.from(imageBuffer).toString('base64');

        console.log('\n>>> SENDING TO GEMINI API <<<');
        console.log('Model: gemini-3-pro-image-preview');
        console.log('Text Prompt Being Sent:', prompt);
        console.log('Image Size:', base64Image.length, 'characters (base64)');

        // Use the correct Google GenAI API pattern
        const promptContent = [
          { text: prompt },
          {
            inlineData: {
              mimeType: 'image/jpeg',
              data: base64Image,
            },
          },
        ];

        console.log('Full Request Structure:');
        console.log('- Text part:', promptContent[0]);
        console.log('- Image part: base64 image data (', base64Image.length, 'chars )');
        console.log('>>> END GEMINI API REQUEST <<<\n');

        const response = await this.ai.models.generateContent({
          model: 'gemini-3-pro-image-preview',
          contents: promptContent,
        });

        console.log('>>> GEMINI API RESPONSE RECEIVED <<<');

        // Check if the response contains generated image data
        const candidates = response.candidates;
        if (!candidates || candidates.length === 0) {
          throw new Error('No image generated by Gemini');
        }

        // Extract generated image data from the response parts
        const parts = candidates[0]?.content?.parts;
        if (!parts) {
          throw new Error('No content parts in Gemini response');
        }

        // Find the image part
        const imagePart = parts.find(part => part.inlineData);
        if (!imagePart?.inlineData?.data) {
          throw new Error('No image data in Gemini response');
        }

        const generatedImageBuffer = Buffer.from(imagePart.inlineData.data, 'base64');

        // Upload to S3 if URL provided
        if (s3UploadUrl) {
          const uploadResponse = await fetch(s3UploadUrl, {
            method: 'PUT',
            body: generatedImageBuffer,
            headers: {
              'Content-Type': 'image/jpeg',
            },
          });

          if (!uploadResponse.ok) {
            throw new Error(`Failed to upload to S3: ${uploadResponse.statusText}`);
          }

          logger.info('Successfully generated and uploaded image', {
            requestId,
            scenario,
            imageSize: generatedImageBuffer.length,
            prompt
          });

          return {
            imageUrl: s3UploadUrl.split('?')[0], // Remove query params to get final URL
          };
        }

        logger.info('Image generated successfully', {
          requestId,
          scenario,
          imageSize: generatedImageBuffer.length,
        });

        return {
          // Return base64 data if no S3 upload URL provided
          imageUrl: `data:image/jpeg;base64,${imagePart.inlineData.data}`,
        };
      });

      return {
        requestId,
        ...result,
      };

    } catch (error) {
      logger.error('Gemini image generation failed', {
        requestId,
        error: error instanceof Error ? error.message : error,
      });

      return {
        requestId,
        error: error instanceof Error ? error.message : 'Image generation failed',
      };
    }
  }

  private generateRequestId(): string {
    return `gemini_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  }

  async healthCheck(): Promise<boolean> {
    try {
      const response = await this.withRetry(async () => {
        return await this.ai.models.generateContent({
          model: 'gemini-3-pro-preview',
          contents: [{ text: 'Hello, this is a health check.' }],
        });
      });
      return !!(response.candidates && response.candidates.length > 0);
    } catch (error) {
      logger.error('Gemini health check failed', error);
      return false;
    }
  }
}

export const geminiService = new GeminiService();
export default geminiService;